{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kR0SKBDbaOqR"
      },
      "source": [
        "# Neural Graphics Ex1: Training Your Own Diffusion Model!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ryMrLOORbWLz"
      },
      "source": [
        "## Setup environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "lX3XpcGSXBIs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5dc23e69-96b7-4722-d842-dbc108ce5522"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.6 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m67.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m33.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "# We recommend using these utils.\n",
        "# https://google.github.io/mediapy/mediapy.html\n",
        "# https://einops.rocks/\n",
        "!pip install mediapy einops --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "VdFQ6c9-Pm4Y"
      },
      "outputs": [],
      "source": [
        "# Import essential modules. Feel free to add whatever you need.\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.datasets import MNIST\n",
        "from torchvision.transforms import ToTensor\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Seed your work\n",
        "To be able to reproduce your code, please use a random seed from this point onward."
      ],
      "metadata": {
        "id": "pDJ3QzHdRV52"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def seed_everything(seed):\n",
        "  torch.cuda.manual_seed(seed)\n",
        "  torch.manual_seed(seed)\n",
        "\n",
        "YOUR_SEED = 180 # modify if you want\n",
        "seed_everything(YOUR_SEED)"
      ],
      "metadata": {
        "id": "aDVpoyjaRcoC"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dokvxybn_DwK"
      },
      "source": [
        "## 1. Basic Ops and UNet blocks\n",
        "**Notations:**  \n",
        " * `Conv2D(kernel_size, stride, padding)` is `nn.Conv2d()`  \n",
        " * `BN` is `nn.BatchNorm2d()`  \n",
        " * `GELU` is `nn.GELU()`  \n",
        " * `ConvTranspose2D(kernel_size, stride, padding)` is `nn.ConvTranspose2d()`  \n",
        " * `AvgPool(kernel_size)` is `nn.AvgPool2d()`  \n",
        " * `Linear` is `nn.Linear()`  \n",
        " * `N`, `C`, `W` and `H` are batch size, channels num, weight and height respectively\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Basic Ops"
      ],
      "metadata": {
        "id": "k1iFNqV8HjzM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "fhpEzgwCJqbW"
      },
      "outputs": [],
      "source": [
        "class Conv(nn.Module):\n",
        "    \"\"\"\n",
        "    A convolutional layer that doesn’t change the image\n",
        "    resolution, only the channel dimension\n",
        "    Applies nn.Conv2d(3, 1, 1) followed by BN and GELU.\n",
        "    \"\"\"\n",
        "    def __init__(self, in_channels: int, out_channels: int):\n",
        "        \"\"\"\n",
        "        Initializes the Conv layer\n",
        "        Args:\n",
        "            in_channels (int): The number of input channels\n",
        "            out_channels (int): The number of output channels\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        #YOUR CODE HERE\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            x: (N, in_channels, H, W) input tensor.\n",
        "\n",
        "        Returns:\n",
        "            (N, out_channels, H, W) output tensor.\n",
        "        \"\"\"\n",
        "        #YOUR CODE HERE\n",
        "        raise NotImplementedError()\n",
        "\n",
        "class DownConv(nn.Module):\n",
        "    \"\"\"\n",
        "        A convolutional layer downsamples the tensor by 2.\n",
        "        The layer consists of Conv2D(3, 2, 1) followed by BN and GELU.\n",
        "    \"\"\"\n",
        "    def __init__(self, in_channels: int, out_channels: int):\n",
        "        \"\"\"\n",
        "        Initializes the DownConv layer\n",
        "        Args:\n",
        "            in_channels (int): The number of input channels\n",
        "            out_channels (int): The number of output channels\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        #YOUR CODE HERE\n",
        "\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            x: (N, in_channels, H, W) input tensor.\n",
        "\n",
        "        Returns:\n",
        "            (N, out_channels, H/2, W/2) output tensor.\n",
        "        \"\"\"\n",
        "        #YOUR CODE HERE\n",
        "        raise NotImplementedError()\n",
        "\n",
        "\n",
        "class UpConv(nn.Module):\n",
        "    \"\"\"\n",
        "    A convolutional layer that upsamples the tensor by 2.\n",
        "    The layer consists of ConvTranspose2d(4, 2, 1) followed by\n",
        "    BN and GELU.\n",
        "    \"\"\"\n",
        "    def __init__(self, in_channels: int, out_channels: int):\n",
        "        \"\"\"\n",
        "        Initializes the UpConv layer\n",
        "        Args:\n",
        "            in_channels (int): The number of input channels\n",
        "            out_channels (int): The number of output channels\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        #YOUR CODE HERE\n",
        "\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            x: (N, in_channels, H, W) input tensor.\n",
        "\n",
        "        Returns:\n",
        "            (N, out_channels, H*2, W*2) output tensor.\n",
        "        \"\"\"\n",
        "        #YOUR CODE HERE\n",
        "        raise NotImplementedError()\n",
        "\n",
        "\n",
        "class Flatten(nn.Module):\n",
        "    \"\"\"\n",
        "    Average pooling layer that flattens a 7x7 tensor into a 1x1 tensor.\n",
        "    The layer consists of AvgPool followed by GELU.\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        #YOUR CODE HERE\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            x: (N, C, 7, 7) input tensor.\n",
        "\n",
        "        Returns:\n",
        "            (N, C, 1, 1) output tensor.\n",
        "        \"\"\"\n",
        "        #YOUR CODE HERE\n",
        "        raise NotImplementedError()\n",
        "\n",
        "\n",
        "class Unflatten(nn.Module):\n",
        "    \"\"\"\n",
        "      Convolutional layer that unflattens/upsamples a 1x1 tensor into a\n",
        "      7x7 tensor. The layer consists of ConvTranspose2D(7, 7, 0)\n",
        "      followed by BN and GELU.\n",
        "    \"\"\"\n",
        "    def __init__(self, in_channels: int):\n",
        "        \"\"\"\n",
        "        Initializes Unflatten layer\n",
        "        Args:\n",
        "            in_channels (int): The number of input channels\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        #YOUR CODE HERE\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            x: (N, in_channels, 1, 1) input tensor.\n",
        "\n",
        "        Returns:\n",
        "            (N, in_channels, 7, 7) output tensor.\n",
        "        \"\"\"\n",
        "        #YOUR CODE HERE\n",
        "        raise NotImplementedError()\n",
        "\n",
        "class FC(nn.Module):\n",
        "    \"\"\"\n",
        "    Fully connected layer, consisting of nn.linear followed by GELU.\n",
        "    \"\"\"\n",
        "    def __init__(self, in_channels: int, out_channels: int):\n",
        "        \"\"\"\n",
        "        Initializes the FC layer\n",
        "        Args:\n",
        "            in_channels (int): The number of input channels\n",
        "            out_channels (int): The number of output channels\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        #YOUR CODE HERE\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            x: (N, in_channels) input tensor.\n",
        "\n",
        "        Returns:\n",
        "            (N, out_channels) output tensor.\n",
        "        \"\"\"\n",
        "        #YOUR CODE HERE\n",
        "        raise NotImplementedError()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### UNet Blocks"
      ],
      "metadata": {
        "id": "GCawfhu0HqcH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ConvBlock(nn.Module):\n",
        "    \"\"\"\n",
        "    Two consecutive Conv operations.\n",
        "    Note that it has the same input and output shape as Conv.\n",
        "    \"\"\"\n",
        "    def __init__(self, in_channels: int, out_channels: int):\n",
        "        \"\"\"\n",
        "        Initializes ConvBlock\n",
        "        Args:\n",
        "            in_channels (int): The number of input channels\n",
        "            out_channels (int): The number of output channels\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        #YOUR CODE HERE\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            x: (N, in_channels, H, W) input tensor.\n",
        "\n",
        "        Returns:\n",
        "            (N, out_channels, H, W) output tensor.\n",
        "        \"\"\"\n",
        "        #YOUR CODE HERE\n",
        "        raise NotImplementedError()\n",
        "\n",
        "\n",
        "class DownBlock(nn.Module):\n",
        "    \"\"\"\n",
        "    DownConv followed by ConvBlock. Note that it has the same input and output\n",
        "    shape as DownConv.\n",
        "    \"\"\"\n",
        "    def __init__(self, in_channels: int, out_channels: int):\n",
        "        \"\"\"\n",
        "        Initializes DownBlock\n",
        "        Args:\n",
        "            in_channels (int): The number of input channels\n",
        "            out_channels (int): The number of output channels\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        #YOUR CODE HERE\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            x: (N, in_channels, H, W) input tensor.\n",
        "\n",
        "        Returns:\n",
        "            (N, out_channels, H/2, W/2) output tensor.\n",
        "        \"\"\"\n",
        "        #YOUR CODE HERE\n",
        "        raise NotImplementedError()\n",
        "\n",
        "\n",
        "class UpBlock(nn.Module):\n",
        "    \"\"\"\n",
        "    UpConv followed by ConvBlock.\n",
        "    Note that it has the same input and output shape as UpConv\n",
        "    \"\"\"\n",
        "    def __init__(self, in_channels: int, out_channels: int):\n",
        "        \"\"\"\n",
        "        Initializes UpBlock\n",
        "        Args:\n",
        "            in_channels (int): The number of input channels\n",
        "            out_channels (int): The number of output channels\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        #YOUR CODE HERE\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            x: (N, in_channels, H, W) input tensor.\n",
        "\n",
        "        Returns:\n",
        "            (N, out_channels, H*2, W*2) output tensor.\n",
        "        \"\"\"\n",
        "        #YOUR CODE HERE\n",
        "        raise NotImplementedError()\n",
        "\n",
        "class FCBlock(nn.Module):\n",
        "    \"\"\"\n",
        "    Fully-connected Block, consisting of FC layer followed by Linear layer. Note\n",
        "    that it has the same input and output shape as FC.\n",
        "    \"\"\"\n",
        "    def __init__(self, in_channels: int, out_channels: int):\n",
        "        \"\"\"\n",
        "        Initializes FCBlock\n",
        "        Args:\n",
        "            in_channels (int): The number of input channels\n",
        "            out_channels (int): The number of output channels\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        #YOUR CODE HERE\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            x: (N, in_channels) input tensor.\n",
        "\n",
        "        Returns:\n",
        "            (N, out_channels) output tensor.\n",
        "        \"\"\"\n",
        "        #YOUR CODE HERE\n",
        "        raise NotImplementedError()"
      ],
      "metadata": {
        "id": "3nusVuFlHt67"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zMI3IMkjayxQ"
      },
      "source": [
        "## 2. Unconditional Diffusion Framework\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.1 UNet architecture"
      ],
      "metadata": {
        "id": "t9JhNQN5Ad3V"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fkchbyYkzAvV"
      },
      "outputs": [],
      "source": [
        "class DenoisingUNet(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        in_channels: int,\n",
        "        num_hiddens: int\n",
        "    ):\n",
        "        super().__init__()\n",
        "        #YOUR CODE HERE\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        x: torch.Tensor,\n",
        "        t: torch.Tensor,\n",
        "    ) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            x: (N, C, H, W) input tensor.\n",
        "            t: (N, 1) normalized time tensor.\n",
        "\n",
        "        Returns:\n",
        "            (N, C, H, W) output tensor.\n",
        "        \"\"\"\n",
        "        assert x.shape[-2:] == (28, 28), \"Expect input shape to be (28, 28).\"\n",
        "        #YOUR CODE HERE\n",
        "        raise NotImplementedError()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0nyxOM-RbZnC"
      },
      "source": [
        "### 2.1 DDPM Forward and Inverse Process\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "yIvMw63T6JkE"
      },
      "outputs": [],
      "source": [
        "def ddpm_schedule(beta1: float, beta2: float, num_ts: int, device: str = 'cuda') -> dict:\n",
        "    \"\"\"Constants for DDPM training and sampling.\n",
        "\n",
        "    Arguments:\n",
        "        beta1: float, starting beta value.\n",
        "        beta2: float, ending beta value.\n",
        "        num_ts: int, number of timesteps.\n",
        "\n",
        "    Returns:\n",
        "        dict with keys:\n",
        "            betas: linear schedule of betas from beta1 to beta2.\n",
        "            alphas: 1 - betas.\n",
        "            alpha_bars: cumulative product of alphas.\n",
        "    \"\"\"\n",
        "    assert beta1 < beta2 < 1.0, \"Expect beta1 < beta2 < 1.0.\"\n",
        "    raise NotImplementedError()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hfvtHEFf_7Q3"
      },
      "outputs": [],
      "source": [
        "def ddpm_forward(\n",
        "    unet: DenoisingUNet,\n",
        "    ddpm_schedule: dict,\n",
        "    x_0: torch.Tensor,\n",
        "    num_ts: int,\n",
        ") -> torch.Tensor:\n",
        "    \"\"\"Algorithm 1 of the DDPM paper (not including gradient step).\n",
        "\n",
        "    Args:\n",
        "        unet: DenoisingUNet\n",
        "        ddpm_schedule: dict\n",
        "        x_0: (N, C, H, W) input tensor.\n",
        "        num_ts: int, number of timesteps.\n",
        "    Returns:\n",
        "        (,) diffusion loss.\n",
        "    \"\"\"\n",
        "    unet.train()\n",
        "    # YOUR CODE HERE.\n",
        "    raise NotImplementedError()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BNE8-455IDm3"
      },
      "outputs": [],
      "source": [
        "@torch.inference_mode()\n",
        "def ddpm_sample(\n",
        "    unet: DenoisingUNet,\n",
        "    ddpm_schedule: dict,\n",
        "    img_wh: tuple[int, int],\n",
        "    batch_size: int,\n",
        "    num_ts: int\n",
        ") -> torch.Tensor:\n",
        "    \"\"\"Algorithm 2 of the DDPM paper.\n",
        "\n",
        "    Args:\n",
        "        unet: DenoisingUNet\n",
        "        ddpm_schedule: dict\n",
        "        img_wh: (H, W) output image width and height.\n",
        "        num_ts: int, number of timesteps.\n",
        "\n",
        "    Returns:\n",
        "        (N, C, H, W) final sample.\n",
        "    \"\"\"\n",
        "    unet.eval()\n",
        "    # YOUR CODE HERE.\n",
        "\n",
        "    raise NotImplementedError()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G_hVifFyw20j"
      },
      "outputs": [],
      "source": [
        "# Do Not Modify\n",
        "class DDPM(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        unet: DenoisingUNet,\n",
        "        betas: tuple[float, float] = (1e-4, 0.02),\n",
        "        num_ts: int = 300,\n",
        "        p_uncond: float = 0.1,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.unet = unet\n",
        "        self.betas = betas\n",
        "        self.num_ts = num_ts\n",
        "        self.p_uncond = p_uncond\n",
        "        self.ddpm_schedule = ddpm_schedule(betas[0], betas[1], num_ts)\n",
        "\n",
        "        for k, v in ddpm_schedule(betas[0], betas[1], num_ts).items():\n",
        "            self.register_buffer(k, v, persistent=False)\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            x: (N, C, H, W) input tensor.\n",
        "\n",
        "        Returns:\n",
        "            (,) diffusion loss.\n",
        "        \"\"\"\n",
        "        return ddpm_forward(\n",
        "            self.unet, self.ddpm_schedule, x, self.num_ts\n",
        "        )\n",
        "\n",
        "    @torch.inference_mode()\n",
        "    def sample(\n",
        "        self,\n",
        "        img_wh: tuple[int, int],\n",
        "        batch_size: int\n",
        "    ):\n",
        "        return ddpm_sample(\n",
        "            self.unet, self.ddpm_schedule, img_wh, batch_size, self.num_ts\n",
        "        )"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.3 Train your denoiser"
      ],
      "metadata": {
        "id": "ACe_cr2_dv7I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyper parameters - Modify if you wish\n",
        "num_hidden = 128\n",
        "batch_size = 64\n",
        "num_epochs = 20\n",
        "lr = 1e-3\n",
        "img_wh = (28, 28)\n",
        "eval_batch_size=20\n",
        "T=300\n",
        "\n",
        "# Init MNIST data loaders\n",
        "train_data = MNIST(root='./data', train=True, download=True, transform=ToTensor())\n",
        "test_data = MNIST(root='./data', train=False, download=True, transform=ToTensor())\n",
        "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
        "eval_loader = DataLoader(test_data, batch_size=eval_batch_size, shuffle=True) #Not usefull now, but will be for evaluating class-conditioned denoiser (3.3)\n",
        "\n",
        "# Init denoiser and DDPM wrapper\n",
        "denosier_unet = DenoisingUNet(in_channels=1 , num_hiddens=num_hidden)\n",
        "ddpm = DDPM(denosier_unet, num_ts=T)\n",
        "\n",
        "# Optimizer and device setup - Adam optimizer with exponential learning rate decay\n",
        "optimizer = torch.optim.Adam(ddpm.parameters(), lr = lr)\n",
        "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer=optimizer, gamma = 0.1**(1.0/num_epochs))\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "ddpm.to(device)\n",
        "\n",
        "for epoch in tqdm(range(num_epochs)):\n",
        "  ddpm.train()  # Set the model to training mode\n",
        "  epoch_loss = 0.0\n",
        "  for batch, (data, label) in enumerate(train_loader):\n",
        "      optimizer.zero_grad()\n",
        "      data = data.to(device)\n",
        "      loss = ddpm(data)\n",
        "      loss.backward()  # Compute gradients\n",
        "      optimizer.step()  # Update weights\n",
        "      batch_loss = loss.item()\n",
        "      # YOUR CODE HERE.\n",
        "      epoch_loss += batch_loss\n",
        "\n",
        "      if batch % 100 == 0:\n",
        "        print(f\"Epoch [{epoch+1}/{num_epochs}], Step [{batch}/{len(train_loader)}], Loss: {batch_loss:.4f}\")\n",
        "\n",
        "  avg_epoch_loss = epoch_loss / len(train_loader)\n",
        "  print(f\"Epoch [{epoch+1}/{num_epochs}] - Average Loss: {avg_epoch_loss:.4f}\")\n",
        "  scheduler.step()\n",
        "\n",
        "\n",
        "  ddpm.eval() # changes the behaior of BN and Dropouts layers\n",
        "  # YOUR EVAL CODE HERE.\n",
        "\n"
      ],
      "metadata": {
        "id": "VSChVRmJYO7L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Implementing class-conditioned diffusion framework with CFG\n"
      ],
      "metadata": {
        "id": "uW2FBjpn8CTZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###3.1 Adding Class-Conditioning to UNet architecture"
      ],
      "metadata": {
        "id": "irot7PI1I2Gi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ConditionalDenoisingUNet(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        in_channels: int,\n",
        "        num_classes: int,\n",
        "        num_hiddens: int,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        # YOUR CODE HERE.\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        x: torch.Tensor,\n",
        "        c: torch.Tensor,\n",
        "        t: torch.Tensor,\n",
        "        mask: torch.Tensor | None = None,\n",
        "    ) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            x: (N, C, H, W) input tensor.\n",
        "            c: (N, num_classes) float condition tensor.\n",
        "            t: (N, 1) normalized time tensor.\n",
        "            mask: (N, 1) mask tensor. If not None, mask out condition when mask == 0.\n",
        "\n",
        "        Returns:\n",
        "            (N, C, H, W) output tensor.\n",
        "        \"\"\"\n",
        "        assert x.shape[-2:] == (28, 28), \"Expect input shape to be (28, 28).\"\n",
        "        # YOUR CODE HERE.\n",
        "        raise NotImplementedError()"
      ],
      "metadata": {
        "id": "vAXZYlOt8Rzy"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###3.2 DDPM Forward and Inverse Process with CFG"
      ],
      "metadata": {
        "id": "uV3lTJz8IxrE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def ddpm_forward(\n",
        "    unet: ConditionalDenoisingUNet,\n",
        "    ddpm_schedule: dict,\n",
        "    x_0: torch.Tensor,\n",
        "    c: torch.Tensor,\n",
        "    p_uncond: float,\n",
        "    num_ts: int,\n",
        ") -> torch.Tensor:\n",
        "    \"\"\"Algorithm 3 (not including gradient step).\n",
        "\n",
        "    Args:\n",
        "        unet: ConditionalDenoisingUNet\n",
        "        ddpm_schedule: dict\n",
        "        x_0: (N, C, H, W) input tensor.\n",
        "        c: (N,) int64 condition tensor.\n",
        "        p_uncond: float, probability of unconditioning the condition.\n",
        "        num_ts: int, number of timesteps.\n",
        "\n",
        "    Returns:\n",
        "        (,) diffusion loss.\n",
        "    \"\"\"\n",
        "    unet.train()\n",
        "    # YOUR CODE HERE.\n",
        "    raise NotImplementedError()"
      ],
      "metadata": {
        "id": "NobmVh4U8BRP"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.inference_mode()\n",
        "def ddpm_cfg_sample(\n",
        "    unet: ConditionalDenoisingUNet,\n",
        "    ddpm_schedule: dict,\n",
        "    c: torch.Tensor,\n",
        "    img_wh: tuple[int, int],\n",
        "    num_ts: int,\n",
        "    guidance_scale: float = 5.0\n",
        ") -> torch.Tensor:\n",
        "    \"\"\"Algorithm 4.\n",
        "\n",
        "    Args:\n",
        "        unet: ConditionalDenoisingUNet\n",
        "        ddpm_schedule: dict\n",
        "        c: (N,) int64 condition tensor. Only for class-conditional\n",
        "        img_wh: (H, W) output image width and height.\n",
        "        num_ts: int, number of timesteps.\n",
        "        guidance_scale: float, CFG scale.\n",
        "\n",
        "    Returns:\n",
        "        (N, C, H, W) final sample.\n",
        "    \"\"\"\n",
        "    unet.eval()\n",
        "    # YOUR CODE HERE.\n",
        "    raise NotImplementedError()"
      ],
      "metadata": {
        "id": "rMW5YeCi8cqO"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Do Not Modify\n",
        "class DDPM(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        unet: ConditionalDenoisingUNet,\n",
        "        betas: tuple[float, float] = (1e-4, 0.02),\n",
        "        num_ts: int = 300,\n",
        "        p_uncond: float = 0.1,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.unet = unet\n",
        "        self.betas = betas\n",
        "        self.num_ts = num_ts\n",
        "        self.p_uncond = p_uncond\n",
        "        self.ddpm_schedule = ddpm_schedule(betas[0], betas[1], num_ts)\n",
        "\n",
        "    def forward(self, x: torch.Tensor, c: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            x: (N, C, H, W) input tensor.\n",
        "            c: (N,) int64 condition tensor.\n",
        "\n",
        "        Returns:\n",
        "            (,) diffusion loss.\n",
        "        \"\"\"\n",
        "        return ddpm_forward(\n",
        "            self.unet, self.ddpm_schedule, x, c, self.p_uncond, self.num_ts\n",
        "        )\n",
        "\n",
        "    @torch.inference_mode()\n",
        "    def sample(\n",
        "        self,\n",
        "        c: torch.Tensor,\n",
        "        img_wh: tuple[int, int],\n",
        "        guidance_scale: float = 5.0\n",
        "    ):\n",
        "        return ddpm_cfg_sample(\n",
        "            self.unet, self.ddpm_schedule, c, img_wh, self.num_ts, guidance_scale\n",
        "        )"
      ],
      "metadata": {
        "id": "gdQFWwIt8mXh"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###3.3 Train your class-conditioned denoiser"
      ],
      "metadata": {
        "id": "EEGqlFNClOaw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# YOUR CODE HERE."
      ],
      "metadata": {
        "id": "MkAIikcEMFEm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###3.4 Experiment with different guidance sacles"
      ],
      "metadata": {
        "id": "m4iTw-TFGYhA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# YOUR CODE HERE.\n"
      ],
      "metadata": {
        "id": "d9gnGqPOoXT2"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "ryMrLOORbWLz",
        "k1iFNqV8HjzM",
        "GCawfhu0HqcH",
        "t9JhNQN5Ad3V",
        "0nyxOM-RbZnC",
        "m4iTw-TFGYhA"
      ],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "cs180-proj5",
      "language": "python",
      "name": "cs180-proj5"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.15"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}